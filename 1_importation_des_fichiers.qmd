---
title: "Détecter des faux billets"
author: "CME"
format: html
editor: visual
---

## I- Contexte

Vous êtes consultant Data Analyst dans une entreprise spécialisée dans la data. Votre entreprise a décroché une prestation en régie au sein de l’**Organisation nationale de lutte contre le faux-monnayage (ONCFM)**.

![](img/logo_oncfm.png)

Cette institution a pour objectif de mettre en place des méthodes d’identification des contrefaçons des billets en euros. Ils font donc appel à vous, spécialiste de la data, pour mettre en place une modélisation qui serait capable d’identifier automatiquement les vrais des faux billets. Et ce à partir simplement de certaines dimensions du billet et des éléments qui le composent.

Voici le [cahier des charges de l’ONCFM](doc/cahier_des_charges.pdf) ainsi que le [jeu de données](data_raw/billets.csv)

Le client souhaite que vous travailliez directement depuis ses locaux sous la responsabilité de Marie, responsable du projet d’analyse de données à l’ONCFM. Elle vous laissera une grande autonomie pendant votre mission, et vous demande simplement que vous lui présentiez vos résultats une fois la mission terminée. Elle souhaite voir quels sont les traitements et analyses que vous avez réalisés en amont, les différentes pistes explorées pour la construction de l’algorithme, ainsi que le modèle final retenu.

Après avoir lu en détail le cahier des charges, vous vous préparez à vous rendre à l’ONCFM pour prendre vos nouvelles fonctions. Vous notez tout de même un post-it qui se trouve sur le coin de votre bureau, laissé par un de vos collègues :

## II- Importation des fichiers

```{r}
data <- read.csv("data_raw/billets.csv", sep =";")
```

## III- Résumé des datas

```{r}
summary(data)
```

Nous avons un dataframe de 7 colonnes et 1 500 lignes 1 colonne de type character 6 colonnes numériques

## IV- Description des variables

```{r}
if (!require(skimr)) install.packages("skimr")
library(skimr)

skim(data)

```

Nous avons 37 valeurs manquantes dans la colonne margin_low

```{r}
valeur_unique <- unique(data$is_genuine)
print(valeur_unique)
```

Nous avons 2 valeurs uniques dans la colonne is_genuine =\> True ou False

```{r}
valeur_compte <- table(data$is_genuine)
print(valeur_compte)
```

Il y a **500 valeurs False** et **1 000 valeurs True**

### En résumé

Nous avons un tableau regroupant les données de 1 500 billets\

1 colonne décrivant s'il s'agit de vrais ou faux billets :\
- il y a 1 000 vrais billets et 500 faux billets\

6 colonne décrivants le format de ces billets :\
- diagonale\
- hauteur gauche\
- hauteur droite\
- marge basse\
- marge haute\
- longueur\

***37 billets*** n'ont pas l'information de la marge basse dans le tableau.

Nous allons aggréger les données sur la colonnne is_genuine\
Afficher la valeur moyenne de chaque variable pour les lignes False et True

```{r}
if (!require(dplyr)) install.packages("dplyr")

library(dplyr)
```

```{r}
resultats <- data %>%
  group_by(is_genuine) %>%
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE)))

print(resultats)
```

## V- Remplacement des données manquantes

Régression linéaire

```{r}
# Étape 1: Création du modèle de régression linéaire
# Modèle avec toutes les variables disponibles pour prédire margin_low
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data)
```

```{r}
# Étape 2: Prédire les valeurs manquantes
# Créer une copie du dataframe avec les NA
data_na <- data[is.na(data$margin_low), ]
```

```{r}
data_na
```

```{r}
# Prédire les valeurs manquantes
predicted_values <- predict(model, newdata = data_na)
```

```{r}
predicted_values
```

```{r}
# Étape 3: Remplacer les NA par les valeurs prédites
data$margin_low[is.na(data$margin_low)] <- predicted_values
```

```{r}
# Voir le résultat
summary(data$margin_low)
```

```{r}
skim(data)
```

```{r}
# Obtenir les résidus du modèle
residus <- residuals(model)

# Résumé des résidus
summary(residus)

# Visualiser les résidus
hist(residus, main="Distribution des résidus", xlab="Résidus")

```

```{r}
# Résumé du modèle de régression linéaire
summary(model)

```

Le modèle de régression linéaire a été ajusté avec succès, et voici ce que signifient les résultats :

### 1. **Résidus**

Les résidus montrent la différence entre les valeurs observées et les valeurs prédites par le modèle.

-   **Min** : -1.47234
-   **1Q (premier quartile)** : -0.31707
-   **Median** : -0.04168
-   **3Q (troisième quartile)** : 0.27353
-   **Max** : 1.97084

Ces chiffres montrent que la plupart des erreurs de prédiction se situent dans une plage de -1.47 à 1.97, avec une médiane proche de 0, ce qui est un bon signe. La distribution des résidus semble équilibrée, on peut vérifier cela avec un histogramme ou un graphique Q-Q pour confirmer.

### 2. **Coefficients**

Les coefficients indiquent l'effet de chaque variable prédictrice sur la variable dépendante `margin_low`, tout en tenant compte des autres variables.

-   **Intercept (22.99484)** : La valeur de `margin_low` lorsque toutes les autres variables sont à 0 (pas toujours significatif dans la pratique, surtout si les valeurs 0 ne sont pas réalistes pour ces variables).

-   **diagonal (-0.11106)** : Une augmentation d'une unité dans `diagonal` est associée à une diminution de `margin_low` de 0.11106 unités, avec une significativité statistique (p-value = 0.00744).

-   **height_left (0.18412)** : Une augmentation d'une unité dans `height_left` est associée à une augmentation de `margin_low` de 0.18412 unités (très significatif avec p-value = 4.13e-05).

-   **height_right (0.25714)** : Une augmentation d'une unité dans `height_right` est associée à une augmentation de `margin_low` de 0.25714 unités (très significatif, p-value = 2.84e-09).

-   **margin_up (0.25619)** : Une augmentation d'une unité dans `margin_up` est associée à une augmentation de `margin_low` de 0.25619 unités (très significatif, p-value = 7.23e-05).

-   **length (-0.40910)** : Une augmentation d'une unité dans `length` est associée à une diminution de `margin_low` de 0.40910 unités (très significatif, p-value \< 2e-16).

### 3. **Signification statistique**

-   Les p-values indiquent que tous les coefficients sont statistiquement significatifs au niveau de 0.05, voire beaucoup plus bas (beaucoup d'étoiles `***`).
-   **Signif. codes** : Les niveaux de significativité sont indiqués avec `*`, `**`, `***`, etc. Ici, tous les prédicteurs sont très significatifs, sauf l'intercept.

### 4. **Erreur standard résiduelle (Residual Standard Error)**

-   **Residual Standard Error** : 0.4807. C'est l'écart-type des résidus, une mesure de la dispersion des observations autour des prédictions. Cela signifie que, en moyenne, les prédictions de `margin_low` sont à 0.4807 unités des valeurs observées.

### 5. **R-squared et Adjusted R-squared**

-   **Multiple R-squared** : 0.4773. Cela signifie que 47.73% de la variance dans `margin_low` est expliquée par ce modèle.
-   **Adjusted R-squared** : 0.4755. C'est une version ajustée du R-squared qui pénalise l'ajout de prédicteurs non significatifs. Ici, c'est très proche du R-squared, ce qui est bon signe.

### 6. **F-statistic**

-   **F-statistic** : 266.1 avec un p-value très bas (\< 2.2e-16), indiquant que le modèle dans son ensemble est statistiquement significatif.

### Conclusion

Le modèle est relativement bon, avec un R-squared autour de 0.4773, ce qui montre une relation modérée entre les variables prédictrices et `margin_low`. Tous les prédicteurs sont statistiquement significatifs, et l'erreur standard résiduelle est relativement basse, ce qui indique que les prédictions ne s'écartent pas trop des valeurs observées.

Cependant, on pourrait améliorer encore la précision en explorant d'autres modèles, vérifier l'absence de colinéarité entre les prédicteurs, ou en ajoutant d'autres variables si elles sont disponibles. on pourrait aussi vérifier les résidus pour s'assurer qu'ils sont normalement distribués et qu'il n'y a pas de problème avec l'homoscédasticité (variance constante des résidus).

## VI- ACP et Clustering

### 1- Recherche de valeurs aberrantes

```{r}
# Boxplot pour chaque variable numérique
data_numeric <- data %>% select(where(is.numeric))

# Afficher boxplots
par(mfrow = c(2, 3))  # Adapter le nombre de graphiques selon le nombre de variables
for (col in colnames(data_numeric)) {
  boxplot(data_numeric[[col]], main = col, ylab = col)
}

```

```{r}
# Scatter plot entre deux variables
plot(data$diagonal, data$height_left, main = "Diagonale vs. Hauteur gauche", xlab = "Diagonale", ylab = "Hauteur gauche")

```

#### a- Méthode IQR

```{r}
# Calculer l'IQR pour chaque colonne
iqr <- function(x) {
  q3 <- quantile(x, 0.75)
  q1 <- quantile(x, 0.25)
  q3 - q1
}

# Détecter les outliers pour chaque colonne
outliers <- function(x) {
  q1 <- quantile(x, 0.25)
  q3 <- quantile(x, 0.75)
  iqr_value <- iqr(x)
  lower_bound <- q1 - 1.5 * iqr_value
  upper_bound <- q3 + 1.5 * iqr_value
  x < lower_bound | x > upper_bound
}
```

```{r}
# Appliquer la fonction pour détecter les outliers
iqr_outliers_data <- data_numeric %>%
  mutate(across(everything(), ~ outliers(.)))

# Afficher les outliers
print(iqr_outliers_data)
```

```{r}
# Afficher les indices des outliers
iqr_outliers_indices <- which(rowSums(iqr_outliers_data) > 0)
print(iqr_outliers_indices)
```

```{r}
# Afficher les lignes du dataframe original contenant des outliers
data_with_iqr_outliers <- data[iqr_outliers_indices, ]

print(data_with_iqr_outliers)
```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
iqr_count_by_is_genuine <- data_with_iqr_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du résultat
print(iqr_count_by_is_genuine)

```

Il y a 53 lignes d'outliers avec la méthode IQR\
40 lignes concernent des faux billets\
13 lignes concernent de vrais billets

#### b- Méthode Z_score

```{r}
if (!require(tidyverse)) install.packages("tidyverse")

# Charger les bibliothèques nécessaires
library(tidyverse)

# Sélectionner les colonnes numériques
data_numeric <- data %>% select(where(is.numeric))

# Calculer les scores Z
data_z <- scale(data_numeric)

# Vérifier les scores Z
head(data_z)

```

```{r}
summary(data_z)
```

```{r}
# Ajouter les scores Z au dataframe original en conservant la colonne de caractères
data_z_full <- cbind(Row_Index = 1:nrow(data), data %>% select(where(is.character)), as.data.frame(data_z))

# Afficher les premières lignes du nouveau dataframe
head(data_z_full)

```

```{r}
# Visualiser la distribution des scores Z pour la colonne 'diagonal'
ggplot(as.data.frame(data_z), aes(x=diagonal)) + 
  geom_histogram(binwidth=0.5, fill="blue", color="black") + 
  theme_minimal() +
  labs(title="Distribution des scores Z pour la colonne 'diagonal'")
```
On fixe à +3 et -3 la limite de z_score pour identifier les outliers

```{r}
# Identifier les lignes avec des outliers (Z > 3 ou Z < -3)
z_outliers <- data_z_full %>%
  filter(apply(data_z, 1, function(row) any(row > 3 | row < -3)))

# Afficher les outliers
print(z_outliers)

```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
z_count_by_is_genuine <- z_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du résultat
print(z_count_by_is_genuine)

```

```{r}
# Extraire les indices des outliers
z_outliers_indices <- z_outliers$Row_Index
z_outliers_indices
```

Il y a 24 lignes d'outliers avec la méthode du Z_score\
17 lignes concernent des faux billets\
7 lignes concernent de vrais billets

### 2- Suppression des lignes d'outliers

Je vais commencer mon analyse en supprimant les outliers identifiés par la méthode du Z_Score  
Je vais donc supprimer 24 lignes du dataframe original "data"  
je le nommerai "data_without_ouliers_z"  

```{r}
data_without_ouliers_z <- data[-z_outliers_indices, ]
data_without_ouliers_z
```

### 3- ACP


```{r}
if (!require(FactoMineR)) install.packages("FactoMineR")
if (!require(factoextra)) install.packages("factoextra")

library(FactoMineR)
library(factoextra)
```

```{r}
# Extraire les colonnes numériques
datanum_without_ouliers_z <- Filter(is.numeric, data_without_ouliers_z)
```

```{r}
# Réaliser l'ACP sans spécifier ncp
resultat_acp <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, graph = FALSE)

# Extraire les valeurs propres
valeurs_propres <- resultat_acp$eig[,1]
```

```{r}
# Calculer les pourcentages d'inertie expliquée par chaque composante
pourcentage_inertie <- 100 * valeurs_propres / sum(valeurs_propres)
# Calculer l'inertie cumulée
cumulative_inertia <- cumsum(pourcentage_inertie)
```

```{r}
# Créer un graphique avec un seul appel
par(mfrow = c(1, 1)) # Assurez-vous d'avoir une seule fenêtre graphique

# Créer un plot avec des barres pour les pourcentages d'inertie
barplot(pourcentage_inertie, main = "Éboulis des Composantes Principales",
        xlab = "Composante Principale", ylab = "Pourcentage d'Inertie",
        col = "lightblue", border = "blue", ylim = c(0, 100))

# Ajouter la courbe cumulée en superposition sur le même graphique
# Recréer le graphique avec la courbe cumulée en utilisant `plot` pour ne pas effacer les barres
par(new = TRUE) # Permet de superposer le nouveau graphique sur le précédent
plot(cumulative_inertia, type = "o", col = "red", pch = 19, 
     ylim = c(0, 100), xlab = "", ylab = "", axes = FALSE)

# Ajouter une légende
legend("topright", legend = c("Inertie Cumulée (%)"), col = "red", pch = 19, inset = c(0, 0.5))
```


```{r}
# on choisit 4 composantes principales qui représentent 80% de la variance
resultat_acp_optimal <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, ncp = 4, graph = FALSE)

```

```{r}
# Visualiser les individus et les variables pour les premières et dernières combinaisons de composantes
pairs_to_plot <- list(c(1, 2), c(3, 4))  # Choisir les paires de composantes à afficher

# Visualiser les individus et les variables pour les différentes combinaisons de composantes
for (pair in pairs_to_plot) {
# Visualiser les individus
  print(fviz_pca_ind(resultat_acp_optimal, 
                     axes = pair, 
                     col.ind = "cos2", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
                     repel = TRUE) +
        ggtitle(paste("Visualisation des Individus - Composantes", pair[1], "et", pair[2])))
  
  # Visualiser les variables
  print(fviz_pca_var(resultat_acp_optimal, 
                     axes = pair, 
                     col.var = "contrib", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")) +
        ggtitle(paste("Visualisation des Variables - Composantes", pair[1], "et", pair[2])))
}
```

Axes principaux :  
Dim1 (43.3%) : Cet axe explique 43.3% de la variance totale des données.  
Dim2 (17%) : Cet axe explique 17% de la variance totale des données.


Dim1 On observe :  
- une forte contribution positibe de la marge basse (margin_low)  
- une forte contribution négative de la longueur (length)  
une forte valeur de Dim1 indiquera un longueur de billet faible avec une marge basse élevée  

Dim2 On observe :  
- une forte contribution positibe de la diagonale
Une forte valeur de Dim2 indiquera une valeur de diagonale élevée


```{r}
# Extraire les scores des individus
scores <- resultat_acp_optimal$ind$coord

```


```{r}
head(scores)
```

```{r}
# Définir une plage de nombres de clusters à tester
k_values <- 1:10  # Tester de 1 à 10 clusters
wss <- numeric(length(k_values))  # Pour stocker la somme des carrés intra-cluster

# Calculer l'inertie pour chaque nombre de clusters
for (k in k_values) {
  kmeans_result <- kmeans(scores, centers = k, nstart = 25)  # nstart pour la reproductibilité
  wss[k] <- kmeans_result$tot.withinss
}

# Tracer la méthode du coude
plot(k_values, wss, type = "b", pch = 19, col = "blue", 
     xlab = "Nombre de Clusters", ylab = "Somme des Carrés Intra-Cluster",
     main = "Méthode du Coude pour K-means Clustering")
```


```{r}
# Installer et charger le package factoextra si ce n'est pas déjà fait
if (!require(factoextra)) install.packages("factoextra")
library(factoextra)

# Installer et charger le package ggplot2 si ce n'est pas déjà fait
if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

# Visualiser les clusters dans les deux premières composantes principales
plot_clusters <- fviz_cluster(kmeans_result, data = scores,
                              ellipse.type = "euclid",  # Ajouter des ellipses autour des clusters
                              ggtheme = theme_minimal()) +
  ggtitle("Clustering K-means avec 2 Clusters")

# Ajouter les centres des clusters au graphique
centroids <- kmeans_result$centers

plot_clusters + 
  geom_point(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2), 
             color = "red", size = 5, shape = 8) +  # Points rouges pour les centres
  geom_text(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2, label = rownames(centroids)),
            color = "black", vjust = -1, hjust = 1)  # Étiquettes pour les centres


```


```{r}
# Centres des clusters
print(kmeans_result$centers)

```
```{r}
# Taille de chaque cluster
print(kmeans_result$size)

```
```{r}
# Ajouter les résultats du clustering à un DataFrame
data_with_clusters <- data.frame(data_without_ouliers_z, Cluster = kmeans_result$cluster)

# Afficher les premières lignes du DataFrame avec les clusters
head(data_with_clusters)

```

```{r}
count_values  <- data_with_clusters %>%
  group_by(Cluster, is_genuine) %>%
  count()

print(count_values)
  
```

