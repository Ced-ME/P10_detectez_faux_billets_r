---
title: "Détecter des faux billets"
author: "CME"
format: html
editor: visual
---

## I- Contexte

Vous êtes consultant Data Analyst dans une entreprise spécialisée dans la data. Votre entreprise a décroché une prestation en régie au sein de l’**Organisation nationale de lutte contre le faux-monnayage (ONCFM)**.

![](img/logo_oncfm.png)

Cette institution a pour objectif de mettre en place des méthodes d’identification des contrefaçons des billets en euros. Ils font donc appel à vous, spécialiste de la data, pour mettre en place une modélisation qui serait capable d’identifier automatiquement les vrais des faux billets. Et ce à partir simplement de certaines dimensions du billet et des éléments qui le composent.

Voici le [cahier des charges de l’ONCFM](doc/cahier_des_charges.pdf) ainsi que le [jeu de données](data_raw/billets.csv)

Le client souhaite que vous travailliez directement depuis ses locaux sous la responsabilité de Marie, responsable du projet d’analyse de données à l’ONCFM. Elle vous laissera une grande autonomie pendant votre mission, et vous demande simplement que vous lui présentiez vos résultats une fois la mission terminée. Elle souhaite voir quels sont les traitements et analyses que vous avez réalisés en amont, les différentes pistes explorées pour la construction de l’algorithme, ainsi que le modèle final retenu.

Après avoir lu en détail le cahier des charges, vous vous préparez à vous rendre à l’ONCFM pour prendre vos nouvelles fonctions. Vous notez tout de même un post-it qui se trouve sur le coin de votre bureau, laissé par un de vos collègues :

## II- Importation des fichiers

```{r}
data <- read.csv("data_raw/billets.csv", sep =";")
```

## III- Résumé des datas

```{r}
summary(data)
```

Nous avons un dataframe de 7 colonnes et 1 500 lignes 1 colonne de type character 6 colonnes numériques

## IV- Description des variables

```{r}
if (!require(skimr)) install.packages("skimr")
library(skimr)

skim(data)

```

Nous avons 37 valeurs manquantes dans la colonne margin_low

```{r}
valeur_unique <- unique(data$is_genuine)
print(valeur_unique)
```

Nous avons 2 valeurs uniques dans la colonne is_genuine =\> True ou False

```{r}
valeur_compte <- table(data$is_genuine)
print(valeur_compte)
```

Il y a **500 valeurs False** et **1 000 valeurs True**

```{r}
# Calcul des pourcentages
pourcentage <- round(valeur_compte / sum(valeur_compte) * 100, 1)
pourcentage_labels <- paste(pourcentage, "%")

# Définir les marges du graphique (gauche, droite, bas, haut)
par(mar = c(1, 1, 1, 1))

# Définir le rapport d'aspect pour le graphique circulaire
par(pty = "s")

# Création du pie chart avec les labels (sans les valeurs)
pie(valeur_compte, 
    labels = names(valeur_compte), 
    main = "Distribution des valeurs de is_genuine", 
    col = c("purple", "skyblue"), 
    border = "white")

# Calcul des positions des étiquettes
positions <- cumsum(valeur_compte) - valeur_compte / 2
text(x = cos(2 * pi * positions / sum(valeur_compte)) * 0.5, 
     y = sin(2 * pi * positions / sum(valeur_compte)) * 0.5, 
     labels = pourcentage_labels, 
     cex = 1.2, col = "white")

```

### En résumé

Nous avons un tableau regroupant les données de 1 500 billets\

1 colonne décrivant s'il s'agit de vrais ou faux billets :\
- il y a 1 000 vrais billets 66.7% et 500 faux billets 33.3%\

6 colonne décrivants le format de ces billets :\
- diagonale\
- hauteur gauche\
- hauteur droite\
- marge basse\
- marge haute\
- longueur\

***37 billets*** n'ont pas l'information de la marge basse dans le tableau.

Nous allons aggréger les données sur la colonnne is_genuine\
Afficher la valeur moyenne de chaque variable pour les lignes False et True

```{r}
if (!require(dplyr)) install.packages("dplyr")

library(dplyr)
```

```{r}
resultats <- data %>%
  group_by(is_genuine) %>%
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE)))

print(resultats)
```

## V- Remlacement des NaN de la colonne "margin_low"

### 1- Matrice de dispersion / relation entre les variables

Nous allons créer un 'pairplot' ou matrice de dispersion pour afficher les relations entre les variables avec des nuages de points, des histogrammes et des tendances lissées en tenant compte de la valeur de 'is_genius' 'False' ou 'True'  


```{r}
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(GGally)) install.packages("GGally")
library(ggplot2)
library(GGally)
```

```{r}
# Assurer que 'is_genuine' est un facteur
data$is_genuine <- as.factor(data$is_genuine)

# Définir les couleurs pour les niveaux de 'is_genuine'
couleurs <- c("False" = "purple", "True" = "skyblue")

# Créer le pairplot
ggpairs(data, 
        aes(color = is_genuine),
        lower = list(continuous = "points"), # Les graphiques en bas à gauche
        diag = list(continuous = "barDiag"), # Les graphiques sur la diagonale
        upper = list(continuous = "smooth")) + # Les graphiques en haut à droite
  scale_color_manual(values = couleurs) +  # Appliquer la palette de couleurs
  theme_bw() +                            # Appliquer un thème de fond blanc
  theme(panel.grid.major = element_line(color = "darkgray"),
        panel.grid.minor = element_blank()) # Personnaliser les grilles

```

En regardant la distribution de vrais et faux billets (is_genuine) en fonction des variables,\
on remarque une plus grande différence de distribution en fonction de la variable "lenght".\
Cela voudrait dire qu'il y aurait des différences significatives de longueur 'length' entre vrais et faux billets.

Mais il manque des valeurs dans 'margin_low' alors nous allons nous concentrer sur les corrélations qu'il y a entre 'margin_low' et les autres variables.

on voit que 'margin_low' :

-   ne semble pas corrélé à 'diagonal',

-   semble corrélé positivement à 'height_left', 'height_right', 'margin_up',

-   semble corrélé négativement à 'length'.

### 2- Heatmap des relations entre les variables

Nous allons représenter ces corrélations sous forme d'une heatmap

```{r}
if (!require(reshape2)) install.packages("reshape2")
if (!require(RColorBrewer)) install.packages("RColorBrewer")
library(reshape2)
library(RColorBrewer)
```

```{r}
# Calculer la matrice de corrélation
corr_matrix <- cor(data[c('diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length')])

# Remodeler la matrice pour ggplot
melted_corr_matrix <- melt(corr_matrix)

# Créer le heatmap avec ggplot2
ggplot(data = melted_corr_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "yellow") +
  geom_text(aes(label = sprintf("%.2f", value)), vjust = 1, color = "black", size = 3) +
  scale_fill_gradientn(colors = brewer.pal(n = 9, name = "BuPu")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Heatmap de la Matrice de Corrélation", x = "", y = "")
```

La variable la plus corrélée à 'margin_low' est la variable 'length'.  
Le coefficient de corrélation est de -0.67, elle est significativement et négativement corrélée à cette variable.

### 3- Nuage de points 'margin_low' vs 'length'

Nous allons créer un nuage de points pour les variables margin_low et length afin de mieux comprendre leur corrélation.

```{r}
# Créer le scatter plot avec ggplot2
ggplot(data, aes(x = margin_low, y = length, color = is_genuine)) +
  geom_point() +  # Ajouter les points avec la couleur basée sur is_genuine
  scale_color_manual(values = c(True = "skyblue", False = "purple")) +  # Définir les couleurs pour TRUE et FALSE
  labs(title = "Scatter Plot de margin_low vs length",
       x = "Margin Low",
       y = "Length",
       color = "Is Genuine") +  # Ajouter une légende pour la couleur
  theme_minimal() +                # Utiliser un thème minimaliste
  theme(axis.text.x = element_text(angle = 45, hjust = 1), # Rotation des labels si nécessaire
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold")) # Centrer le titre
```
On remarque une tendance grace au scatter plot :
- plus la longueur "length" est faible,  
- plus la marge basse "margin_low" est haute
Cela marque également significativement la différence entre vrais et faux billets :
- les vrais billets ont une longueur élevée et une marge_low faible
- les faux billets ont une longueur faible et une marge_low élevée.

### 4- Vérification de la corrélation entre 'margin_low' et 'length'
#### a- Normalité de la distribution ? viualisation Graphique
##### Histogrammes

```{r}
# Histogramme et courbe de densité pour margin_low
ggplot(data, aes(x = margin_low)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogramme et courbe de densité pour margin_low",
       x = "Margin Low",
       y = "Density") +
  theme_minimal()

# Histogramme et courbe de densité pour length
ggplot(data, aes(x = length)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogramme et courbe de densité pour length",
       x = "Length",
       y = "Density") +
  theme_minimal()

```

##### Q-Q plots

```{r}
# Q-Q Plot pour margin_low
ggplot(data, aes(sample = margin_low)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot pour margin_low",
       x = "Théorique Quantiles",
       y = "Quantiles Observés") +
  theme_minimal()

# Q-Q Plot pour length
ggplot(data, aes(sample = length)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot pour length",
       x = "Théorique Quantiles",
       y = "Quantiles Observés") +
  theme_minimal()

```

#### b- Normalité de la distribution ? tests mathématiques
##### Shapiro-Wilk

H0 : les 2 variables suivent une distribution normale (si p-value > 0.05)
H1 : les 2 variables ne suivent pas une distribution normale (si p-value < 0.05)

```{r}
# Test de Shapiro-Wilk pour margin_low
shapiro_test_margin_low <- shapiro.test(data$margin_low)
print(shapiro_test_margin_low)

# Test de Shapiro-Wilk pour length
shapiro_test_length <- shapiro.test(data$length)
print(shapiro_test_length)

```

H0 est rejetée car au moins une des 2 variables ne suit pas une distribution normale avec p-value < 0.05 et proche de 0.

p-value très faible (< 2.2e-16) :

La p-value très inférieure à 0.05 indique que nous rejetons l'hypothèse nulle dans les deux cas. Autrement dit, il est extrêmement improbable que les données suivent une distribution normale.

Statistiques 
𝑊
W :

Les statistiques 
𝑊
W (0.93752 pour margin_low et 0.9176 pour length) sont inférieures à 1, ce qui suggère que les données s'écartent de la normalité.

Les résultats des tests de Shapiro-Wilk indiquent que ni margin_low ni length ne suivent une distribution normale.

##### Kolmogorov-Smirnov

```{r}
# Test de Kolmogorov-Smirnov pour margin_low
ks_test_margin_low <- ks.test(data$margin_low, "pnorm", mean = mean(data$margin_low), sd = sd(data$margin_low))
print(ks_test_margin_low)

# Test de Kolmogorov-Smirnov pour length
ks_test_length <- ks.test(data$length, "pnorm", mean = mean(data$length), sd = sd(data$length))
print(ks_test_length)

```

Statistique 
𝐷
D :

La statistique 
𝐷
D mesure la plus grande différence entre la distribution empirique des données et la distribution normale théorique. Une statistique 
𝐷
D plus grande indique une plus grande déviation de la normalité.

p-value :

La p-value très faible (< 2.2e-16) indique que nous rejetons l'hypothèse nulle selon laquelle les données suivent une distribution normale. Cela suggère que les données de margin_low et length s'écartent significativement d'une distribution normale.

Les résultats du test de Kolmogorov-Smirnov confirment les conclusions des tests de Shapiro-Wilk : les données ne suivent pas une distribution normale.

#### c- Test de corrélation des rangs de Spearman

Dans le cas d'une distribution non gaussienne nous utilisons le coefficient de corrélation des rangs de Spearman pour déterminer mathématiquement s'il y a une corrélation entre 2 variables quantitatives.

```{r}
# Effectuer le test de corrélation de Spearman entre margin_low et length
test_spearman <- cor.test(data$margin_low, data$length, method = "spearman")

# Afficher les résultats
print(test_spearman)

```

### Régréssion linéaire multiple
#### Vérifier la multicolinéarité avec statistiques VIF (Variance Inflation Factory)

```{r}
if (!require(car)) install.packages("car")
library(car)

# Préparer les données : retirer les lignes avec des valeurs manquantes
data_clean <- na.omit(data[, c("margin_low", "diagonal", "height_left", "height_right", "margin_up", "length")])

# Créer le modèle de régression
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data_clean)

# Calculer les valeurs VIF
vif_values <- vif(model)

# Afficher les valeurs VIF
print(vif_values)
```

Règles Générales :

VIF < 5 : Pas de multicolinéarité significative.
5 ≤ VIF < 10 : Multicolinéarité modérée.
VIF ≥ 10 : Multicolinéarité élevée.

Les résultats montrent que la multicolinéarité entre les variables prédictives n'est pas un problème majeur dans le modèle. Les valeurs VIF sont toutes relativement faibles, ce qui est un bon signe pour la stabilité et l'interprétabilité du modèle de régression linéaire.

#### Validation croisée

La validation croisée permet de tester la performance du modèle sur plusieurs sous-ensembles de données pour évaluer sa capacité à généraliser.

```{r}
if (!require(caret)) install.packages("caret")
library(caret)

# Définir les contrôles de validation croisée
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

# Créer le modèle de régression
model <- train(margin_low ~ diagonal + height_left + height_right + margin_up + length,
               data = data_clean, 
               method = "lm", 
               trControl = train_control)

# Afficher les résultats de la validation croisée
print(model)
```

#### Analyse des Résidus

Examine les résidus pour vérifier les hypothèses de la régression linéaire, notamment l'homoscédasticité (variance constante des erreurs) et la normalité des résidus.

```{r}
# Créer un modèle de régression
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data_clean)

# Plot des résidus
par(mfrow = c(2, 2))  # Afficher plusieurs graphiques dans une grille 2x2
plot(model)  # Affiche les graphiques des résidus

```
Les graphiques générés sont :

Residuals vs Fitted: Vérifie si les résidus sont aléatoires.
Normal Q-Q: Vérifie la normalité des résidus.
Scale-Location: Vérifie l'homoscédasticité.
Residuals vs Leverage: Identifie les points influents.

#### Évaluation des Performances

Évalue la performance du modèle en utilisant des métriques telles que le R², l'erreur quadratique moyenne (RMSE) et l'erreur absolue moyenne (MAE).

```{r}
# Calculer les prédictions sur les données de validation
predictions <- predict(model, newdata = data_clean)

# Calculer les métriques de performance
actuals <- data_clean$margin_low
rmse <- sqrt(mean((predictions - actuals)^2))
mae <- mean(abs(predictions - actuals))
r_squared <- summary(model)$r.squared

# Afficher les résultats
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

```

RMSE (Root Mean Square Error) : Le RMSE de 0.4746 obtenu lors de la validation croisée et de 0.4733 sur l'ensemble de test montre que le modèle est cohérent entre l'entraînement et le test.
MAE (Mean Absolute Error) : Le MAE de 0.3642 lors de la validation croisée et de 0.3597 sur l'ensemble de test indique que les erreurs moyennes absolues sont également faibles, ce qui est un bon signe.
R² (Coefficient de Détermination) : Un R² d'environ 0.48-0.49 montre que le modèle explique environ 48-49% de la variance des données, ce qui n'est pas exceptionnel, mais peut être satisfaisant en fonction de la complexité du problème.

#### Détection des Points Influents

Il est également important d'identifier les points influents qui pourraient avoir un impact disproportionné sur le modèle.

```{r}
# Calculer les valeurs de Cook's distance
cooks_d <- cooks.distance(model)

# Identifier les points influents
influential_points <- which(cooks_d > (4 / nrow(data_clean)))

# Afficher les points influents
cat("Points influents :", influential_points, "\n")

```

```{r}
# Extraire et afficher les lignes correspondantes dans le dataframe 'data'
influential_data <- data[influential_points, ]
print(influential_data)
```

#### Validation avec un Ensemble de Test

Si possible, réserve un sous-ensemble de tes données pour tester le modèle après l'entraînement. Cela te permettra de vérifier la performance sur des données non vues.

```{r}
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
train_index <- createDataPartition(data_clean$margin_low, p = 0.7, list = FALSE)
train_data <- data_clean[train_index, ]
test_data <- data_clean[-train_index, ]

# Créer et entraîner le modèle sur les données d'entraînement
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = train_data)

# Prédictions sur les données de test
predictions <- predict(model, newdata = test_data)

# Calculer les métriques de performance sur les données de test
actuals <- test_data$margin_low
rmse_test <- sqrt(mean((predictions - actuals)^2))
mae_test <- mean(abs(predictions - actuals))
r_squared_test <- summary(lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = test_data))$r.squared

# Afficher les résultats de la validation sur les données de test
cat("Test RMSE:", rmse_test, "\n")
cat("Test MAE:", mae_test, "\n")
cat("Test R-squared:", r_squared_test, "\n")

```


## V- Remplacement des données manquantes

Régression linéaire

```{r}
# Étape 1: Création du modèle de régression linéaire
# Modèle avec toutes les variables disponibles pour prédire margin_low
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data)
```

```{r}
# Étape 2: Prédire les valeurs manquantes
# Créer une copie du dataframe avec les NA
data_na <- data[is.na(data$margin_low), ]
```

```{r}
data_na
```

```{r}
# Prédire les valeurs manquantes
predicted_values <- predict(model, newdata = data_na)
```

```{r}
predicted_values
```

```{r}
# Étape 3: Remplacer les NA par les valeurs prédites
data$margin_low[is.na(data$margin_low)] <- predicted_values
```

```{r}
# Voir le résultat
summary(data$margin_low)
```

```{r}
skim(data)
```

```{r}
# Obtenir les résidus du modèle
residus <- residuals(model)

# Résumé des résidus
summary(residus)

# Visualiser les résidus
hist(residus, main="Distribution des résidus", xlab="Résidus")

```

```{r}
# Résumé du modèle de régression linéaire
summary(model)

```

Le modèle de régression linéaire a été ajusté avec succès, et voici ce que signifient les résultats :

### 1. **Résidus**

Les résidus montrent la différence entre les valeurs observées et les valeurs prédites par le modèle.

-   **Min** : -1.47234
-   **1Q (premier quartile)** : -0.31707
-   **Median** : -0.04168
-   **3Q (troisième quartile)** : 0.27353
-   **Max** : 1.97084

Ces chiffres montrent que la plupart des erreurs de prédiction se situent dans une plage de -1.47 à 1.97, avec une médiane proche de 0, ce qui est un bon signe. La distribution des résidus semble équilibrée, on peut vérifier cela avec un histogramme ou un graphique Q-Q pour confirmer.

### 2. **Coefficients**

Les coefficients indiquent l'effet de chaque variable prédictrice sur la variable dépendante `margin_low`, tout en tenant compte des autres variables.

-   **Intercept (22.99484)** : La valeur de `margin_low` lorsque toutes les autres variables sont à 0 (pas toujours significatif dans la pratique, surtout si les valeurs 0 ne sont pas réalistes pour ces variables).

-   **diagonal (-0.11106)** : Une augmentation d'une unité dans `diagonal` est associée à une diminution de `margin_low` de 0.11106 unités, avec une significativité statistique (p-value = 0.00744).

-   **height_left (0.18412)** : Une augmentation d'une unité dans `height_left` est associée à une augmentation de `margin_low` de 0.18412 unités (très significatif avec p-value = 4.13e-05).

-   **height_right (0.25714)** : Une augmentation d'une unité dans `height_right` est associée à une augmentation de `margin_low` de 0.25714 unités (très significatif, p-value = 2.84e-09).

-   **margin_up (0.25619)** : Une augmentation d'une unité dans `margin_up` est associée à une augmentation de `margin_low` de 0.25619 unités (très significatif, p-value = 7.23e-05).

-   **length (-0.40910)** : Une augmentation d'une unité dans `length` est associée à une diminution de `margin_low` de 0.40910 unités (très significatif, p-value \< 2e-16).

### 3. **Signification statistique**

-   Les p-values indiquent que tous les coefficients sont statistiquement significatifs au niveau de 0.05, voire beaucoup plus bas (beaucoup d'étoiles `***`).
-   **Signif. codes** : Les niveaux de significativité sont indiqués avec `*`, `**`, `***`, etc. Ici, tous les prédicteurs sont très significatifs, sauf l'intercept.

### 4. **Erreur standard résiduelle (Residual Standard Error)**

-   **Residual Standard Error** : 0.4807. C'est l'écart-type des résidus, une mesure de la dispersion des observations autour des prédictions. Cela signifie que, en moyenne, les prédictions de `margin_low` sont à 0.4807 unités des valeurs observées.

### 5. **R-squared et Adjusted R-squared**

-   **Multiple R-squared** : 0.4773. Cela signifie que 47.73% de la variance dans `margin_low` est expliquée par ce modèle.
-   **Adjusted R-squared** : 0.4755. C'est une version ajustée du R-squared qui pénalise l'ajout de prédicteurs non significatifs. Ici, c'est très proche du R-squared, ce qui est bon signe.

### 6. **F-statistic**

-   **F-statistic** : 266.1 avec un p-value très bas (\< 2.2e-16), indiquant que le modèle dans son ensemble est statistiquement significatif.

### Conclusion

Le modèle est relativement bon, avec un R-squared autour de 0.4773, ce qui montre une relation modérée entre les variables prédictrices et `margin_low`. Tous les prédicteurs sont statistiquement significatifs, et l'erreur standard résiduelle est relativement basse, ce qui indique que les prédictions ne s'écartent pas trop des valeurs observées.

Cependant, on pourrait améliorer encore la précision en explorant d'autres modèles, vérifier l'absence de colinéarité entre les prédicteurs, ou en ajoutant d'autres variables si elles sont disponibles. on pourrait aussi vérifier les résidus pour s'assurer qu'ils sont normalement distribués et qu'il n'y a pas de problème avec l'homoscédasticité (variance constante des résidus).

## VI- ACP et Clustering

### 1- Recherche de valeurs aberrantes

```{r}
# Boxplot pour chaque variable numérique
data_numeric <- data %>% select(where(is.numeric))

# Afficher boxplots
par(mfrow = c(2, 3))  # Adapter le nombre de graphiques selon le nombre de variables
for (col in colnames(data_numeric)) {
  boxplot(data_numeric[[col]], main = col, ylab = col)
}

```

```{r}
# Scatter plot entre deux variables
plot(data$diagonal, data$height_left, main = "Diagonale vs. Hauteur gauche", xlab = "Diagonale", ylab = "Hauteur gauche")

```

#### a- Méthode IQR

```{r}
# Calculer l'IQR pour chaque colonne
iqr <- function(x) {
  q3 <- quantile(x, 0.75)
  q1 <- quantile(x, 0.25)
  q3 - q1
}

# Détecter les outliers pour chaque colonne
outliers <- function(x) {
  q1 <- quantile(x, 0.25)
  q3 <- quantile(x, 0.75)
  iqr_value <- iqr(x)
  lower_bound <- q1 - 1.5 * iqr_value
  upper_bound <- q3 + 1.5 * iqr_value
  x < lower_bound | x > upper_bound
}
```

```{r}
# Appliquer la fonction pour détecter les outliers
iqr_outliers_data <- data_numeric %>%
  mutate(across(everything(), ~ outliers(.)))

# Afficher les outliers
head(iqr_outliers_data)
```

```{r}
# Afficher les indices des outliers
iqr_outliers_indices <- which(rowSums(iqr_outliers_data) > 0)
print(iqr_outliers_indices)
```

```{r}
# Afficher les lignes du dataframe original contenant des outliers
data_with_iqr_outliers <- data[iqr_outliers_indices, ]

print(data_with_iqr_outliers)
```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
iqr_count_by_is_genuine <- data_with_iqr_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du résultat
print(iqr_count_by_is_genuine)

```

Il y a 53 lignes d'outliers avec la méthode IQR\
40 lignes concernent des faux billets\
13 lignes concernent de vrais billets

#### b- Méthode Z_score

```{r}
if (!require(tidyverse)) install.packages("tidyverse")

# Charger les bibliothèques nécessaires
library(tidyverse)

# Sélectionner les colonnes numériques
data_numeric <- data %>% select(where(is.numeric))

# Calculer les scores Z
data_z <- scale(data_numeric)

# Vérifier les scores Z
head(data_z)

```

```{r}
summary(data_z)
```

```{r}
# Ajouter les scores Z au dataframe original en conservant la colonne de caractères
data_z_full <- cbind(Row_Index = 1:nrow(data), data %>% select(where(is.character)), as.data.frame(data_z))

# Afficher les premières lignes du nouveau dataframe
head(data_z_full)

```

```{r}
# Visualiser la distribution des scores Z pour la colonne 'diagonal'
ggplot(as.data.frame(data_z), aes(x=diagonal)) + 
  geom_histogram(binwidth=0.5, fill="blue", color="black") + 
  theme_minimal() +
  labs(title="Distribution des scores Z pour la colonne 'diagonal'")
```

On fixe à +3 et -3 la limite de z_score pour identifier les outliers

```{r}
# Identifier les lignes avec des outliers (Z > 3 ou Z < -3)
z_outliers <- data_z_full %>%
  filter(apply(data_z, 1, function(row) any(row > 3 | row < -3)))

# Afficher les outliers
print(z_outliers)

```
```{r}
data_bis <- data
# Ajouter une colonne Row_index basée sur l'index de ligne
data_bis$Row_Index <- 1:nrow(data_bis)

```


```{r}
data_bis
```

```{r}
# Fusionner z_outliers avec la colonne is_genuine de data en utilisant Row_index
z_outliers <- merge(z_outliers, data_bis[, c("Row_Index", "is_genuine")], by = "Row_Index")

z_outliers
```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
z_count_by_is_genuine <- z_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du résultat
print(z_count_by_is_genuine)

```

```{r}
# Extraire les indices des outliers
z_outliers_indices <- z_outliers$Row_Index
z_outliers_indices
```

Il y a 24 lignes d'outliers avec la méthode du Z_score\
17 lignes concernent des faux billets\
7 lignes concernent de vrais billets

### 2- Suppression des lignes d'outliers

Je vais commencer mon analyse en supprimant les outliers identifiés par la méthode du Z_Score\
Je vais donc supprimer 24 lignes du dataframe original "data"\
je le nommerai "data_without_ouliers_z"

```{r}
data_without_ouliers_z <- data[-z_outliers_indices, ]
data_without_ouliers_z
```

### 3- ACP

```{r}
if (!require(FactoMineR)) install.packages("FactoMineR")
if (!require(factoextra)) install.packages("factoextra")

library(FactoMineR)
library(factoextra)
```

```{r}
# Extraire les colonnes numériques
datanum_without_ouliers_z <- Filter(is.numeric, data_without_ouliers_z)
```

```{r}
# Réaliser l'ACP sans spécifier ncp
resultat_acp <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, graph = FALSE)

# Extraire les valeurs propres
valeurs_propres <- resultat_acp$eig[,1]
```

```{r}
# Calculer les pourcentages d'inertie expliquée par chaque composante
pourcentage_inertie <- 100 * valeurs_propres / sum(valeurs_propres)
# Calculer l'inertie cumulée
cumulative_inertia <- cumsum(pourcentage_inertie)
```

```{r}
# Créer un graphique avec un seul appel
par(mfrow = c(1, 1)) # Assurez-vous d'avoir une seule fenêtre graphique

# Créer un plot avec des barres pour les pourcentages d'inertie
barplot(pourcentage_inertie, main = "Éboulis des Composantes Principales",
        xlab = "Composante Principale", ylab = "Pourcentage d'Inertie",
        col = "lightblue", border = "blue", ylim = c(0, 100))

# Ajouter la courbe cumulée en superposition sur le même graphique
# Recréer le graphique avec la courbe cumulée en utilisant `plot` pour ne pas effacer les barres
par(new = TRUE) # Permet de superposer le nouveau graphique sur le précédent
plot(cumulative_inertia, type = "o", col = "red", pch = 19, 
     ylim = c(0, 100), xlab = "", ylab = "", axes = FALSE)

# Ajouter une légende
legend("topright", legend = c("Inertie Cumulée (%)"), col = "red", pch = 19, inset = c(0, 0.5))
```

```{r}
# on choisit 4 composantes principales qui représentent 80% de la variance
resultat_acp_optimal <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, ncp = 4, graph = FALSE)

```

```{r}
# Visualiser les individus et les variables pour les premières et dernières combinaisons de composantes
pairs_to_plot <- list(c(1, 2), c(3, 4))  # Choisir les paires de composantes à afficher

# Visualiser les individus et les variables pour les différentes combinaisons de composantes
for (pair in pairs_to_plot) {
# Visualiser les individus
  print(fviz_pca_ind(resultat_acp_optimal, 
                     axes = pair, 
                     col.ind = "cos2", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
                     repel = TRUE) +
        ggtitle(paste("Visualisation des Individus - Composantes", pair[1], "et", pair[2])))
  
  # Visualiser les variables
  print(fviz_pca_var(resultat_acp_optimal, 
                     axes = pair, 
                     col.var = "contrib", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")) +
        ggtitle(paste("Visualisation des Variables - Composantes", pair[1], "et", pair[2])))
}
```

Axes principaux :\
Dim1 (45.9%) : Cet axe explique 45.9% de la variance totale des données.\
Dim2 (14.6%) : Cet axe explique 14.6% de la variance totale des données.

Dim1 On observe :\
- une forte contribution positibe de la marge basse (margin_low)\
- une forte contribution négative de la longueur (length)\
une forte valeur de Dim1 indiquera un longueur de billet faible avec une marge basse élevée

Dim2 On observe :\
- une forte contribution positibe de la diagonale Une forte valeur de Dim2 indiquera une valeur de diagonale élevée

```{r}
# Extraire les scores des individus
scores <- resultat_acp_optimal$ind$coord

```

```{r}
head(scores)
```

### 4- Clustering

```{r}
# Définir une plage de nombres de clusters à tester
k_values <- 1:10  # Tester de 1 à 10 clusters
wss <- numeric(length(k_values))  # Pour stocker la somme des carrés intra-cluster

# Calculer l'inertie pour chaque nombre de clusters
for (k in k_values) {
  kmeans_result <- kmeans(scores, centers = k, nstart = 25)  # nstart pour la reproductibilité
  wss[k] <- kmeans_result$tot.withinss
}

# Tracer la méthode du coude
plot(k_values, wss, type = "b", pch = 19, col = "blue", 
     xlab = "Nombre de Clusters", ylab = "Somme des Carrés Intra-Cluster",
     main = "Méthode du Coude pour K-means Clustering")
```

```{r}
# Appliquer K-means clustering avec 2 clusters
kmeans_result <- kmeans(scores, centers = 2, nstart = 23)  # nstart pour la reproductibilité

```

```{r}
# Installer et charger le package factoextra si ce n'est pas déjà fait
if (!require(factoextra)) install.packages("factoextra")
library(factoextra)

# Installer et charger le package ggplot2 si ce n'est pas déjà fait
if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

# Visualiser les clusters dans les deux premières composantes principales
plot_clusters <- fviz_cluster(kmeans_result, data = scores,
                              ellipse.type = "euclid",  # Ajouter des ellipses autour des clusters
                              ggtheme = theme_minimal()) +
  ggtitle("Clustering K-means avec 2 Clusters")

# Ajouter les centres des clusters au graphique
centroids <- kmeans_result$centers

plot_clusters + 
  geom_point(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2), 
             color = "red", size = 5, shape = 8) +  # Points rouges pour les centres
  geom_text(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2, label = rownames(centroids)),
            color = "black", vjust = -1, hjust = 1)  # Étiquettes pour les centres


```

```{r}
# Centres des clusters
print(kmeans_result$centers)

```

```{r}
# Taille de chaque cluster
print(kmeans_result$size)

```

```{r}
# Ajouter les résultats du clustering à un DataFrame
data_with_clusters <- data.frame(data_without_ouliers_z, Cluster = kmeans_result$cluster)

# Afficher les premières lignes du DataFrame avec les clusters
head(data_with_clusters)

```

```{r}
count_values  <- data_with_clusters %>%
  group_by(Cluster, is_genuine) %>%
  count()

print(count_values)
  
```
