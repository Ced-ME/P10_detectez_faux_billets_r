---
title: "D√©tecter des faux billets"
author: "CME"
format: html
editor: visual
---

## I- Contexte

Vous √™tes consultant Data Analyst dans une entreprise sp√©cialis√©e dans la data. Votre entreprise a d√©croch√© une prestation en r√©gie au sein de l‚Äô**Organisation nationale de lutte contre le faux-monnayage (ONCFM)**.

![](img/logo_oncfm.png)

Cette institution a pour objectif de mettre en place des m√©thodes d‚Äôidentification des contrefa√ßons des billets en euros. Ils font donc appel √† vous, sp√©cialiste de la data, pour mettre en place une mod√©lisation qui serait capable d‚Äôidentifier automatiquement les vrais des faux billets. Et ce √† partir simplement de certaines dimensions du billet et des √©l√©ments qui le composent.

Voici le [cahier des charges de l‚ÄôONCFM](doc/cahier_des_charges.pdf) ainsi que le [jeu de donn√©es](data_raw/billets.csv)

Le client souhaite que vous travailliez directement depuis ses locaux sous la responsabilit√© de Marie, responsable du projet d‚Äôanalyse de donn√©es √† l‚ÄôONCFM. Elle vous laissera une grande autonomie pendant votre mission, et vous demande simplement que vous lui pr√©sentiez vos r√©sultats une fois la mission termin√©e. Elle souhaite voir quels sont les traitements et analyses que vous avez r√©alis√©s en amont, les diff√©rentes pistes explor√©es pour la construction de l‚Äôalgorithme, ainsi que le mod√®le final retenu.

Apr√®s avoir lu en d√©tail le cahier des charges, vous vous pr√©parez √† vous rendre √† l‚ÄôONCFM pour prendre vos nouvelles fonctions. Vous notez tout de m√™me un post-it qui se trouve sur le coin de votre bureau, laiss√© par un de vos coll√®gues :

## II- Importation des fichiers

```{r}
data <- read.csv("data_raw/billets.csv", sep =";")
```

## III- R√©sum√© des datas

```{r}
summary(data)
```

Nous avons un dataframe de 7 colonnes et 1 500 lignes 1 colonne de type character 6 colonnes num√©riques

## IV- Description des variables

```{r}
if (!require(skimr)) install.packages("skimr")
library(skimr)

skim(data)

```

Nous avons 37 valeurs manquantes dans la colonne margin_low

```{r}
valeur_unique <- unique(data$is_genuine)
print(valeur_unique)
```

Nous avons 2 valeurs uniques dans la colonne is_genuine =\> True ou False

```{r}
valeur_compte <- table(data$is_genuine)
print(valeur_compte)
```

Il y a **500 valeurs False** et **1 000 valeurs True**

```{r}
# Calcul des pourcentages
pourcentage <- round(valeur_compte / sum(valeur_compte) * 100, 1)
pourcentage_labels <- paste(pourcentage, "%")

# D√©finir les marges du graphique (gauche, droite, bas, haut)
par(mar = c(1, 1, 1, 1))

# D√©finir le rapport d'aspect pour le graphique circulaire
par(pty = "s")

# Cr√©ation du pie chart avec les labels (sans les valeurs)
pie(valeur_compte, 
    labels = names(valeur_compte), 
    main = "Distribution des valeurs de is_genuine", 
    col = c("purple", "skyblue"), 
    border = "white")

# Calcul des positions des √©tiquettes
positions <- cumsum(valeur_compte) - valeur_compte / 2
text(x = cos(2 * pi * positions / sum(valeur_compte)) * 0.5, 
     y = sin(2 * pi * positions / sum(valeur_compte)) * 0.5, 
     labels = pourcentage_labels, 
     cex = 1.2, col = "white")

```

### En r√©sum√©

Nous avons un tableau regroupant les donn√©es de 1 500 billets\

1 colonne d√©crivant s'il s'agit de vrais ou faux billets :\
- il y a 1 000 vrais billets 66.7% et 500 faux billets 33.3%\

6 colonne d√©crivants le format de ces billets :\
- diagonale\
- hauteur gauche\
- hauteur droite\
- marge basse\
- marge haute\
- longueur\

***37 billets*** n'ont pas l'information de la marge basse dans le tableau.

Nous allons aggr√©ger les donn√©es sur la colonnne is_genuine\
Afficher la valeur moyenne de chaque variable pour les lignes False et True

```{r}
if (!require(dplyr)) install.packages("dplyr")

library(dplyr)
```

```{r}
resultats <- data %>%
  group_by(is_genuine) %>%
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE)))

print(resultats)
```

## V- Remlacement des NaN de la colonne "margin_low"

### 1- Matrice de dispersion / relation entre les variables

Nous allons cr√©er un 'pairplot' ou matrice de dispersion pour afficher les relations entre les variables avec des nuages de points, des histogrammes et des tendances liss√©es en tenant compte de la valeur de 'is_genius' 'False' ou 'True'  


```{r}
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(GGally)) install.packages("GGally")
library(ggplot2)
library(GGally)
```

```{r}
# Assurer que 'is_genuine' est un facteur
data$is_genuine <- as.factor(data$is_genuine)

# D√©finir les couleurs pour les niveaux de 'is_genuine'
couleurs <- c("False" = "purple", "True" = "skyblue")

# Cr√©er le pairplot
ggpairs(data, 
        aes(color = is_genuine),
        lower = list(continuous = "points"), # Les graphiques en bas √† gauche
        diag = list(continuous = "barDiag"), # Les graphiques sur la diagonale
        upper = list(continuous = "smooth")) + # Les graphiques en haut √† droite
  scale_color_manual(values = couleurs) +  # Appliquer la palette de couleurs
  theme_bw() +                            # Appliquer un th√®me de fond blanc
  theme(panel.grid.major = element_line(color = "darkgray"),
        panel.grid.minor = element_blank()) # Personnaliser les grilles

```

En regardant la distribution de vrais et faux billets (is_genuine) en fonction des variables,\
on remarque une plus grande diff√©rence de distribution en fonction de la variable "lenght".\
Cela voudrait dire qu'il y aurait des diff√©rences significatives de longueur 'length' entre vrais et faux billets.

Mais il manque des valeurs dans 'margin_low' alors nous allons nous concentrer sur les corr√©lations qu'il y a entre 'margin_low' et les autres variables.

on voit que 'margin_low' :

-   ne semble pas corr√©l√© √† 'diagonal',

-   semble corr√©l√© positivement √† 'height_left', 'height_right', 'margin_up',

-   semble corr√©l√© n√©gativement √† 'length'.

### 2- Heatmap des relations entre les variables

Nous allons repr√©senter ces corr√©lations sous forme d'une heatmap

```{r}
if (!require(reshape2)) install.packages("reshape2")
if (!require(RColorBrewer)) install.packages("RColorBrewer")
library(reshape2)
library(RColorBrewer)
```

```{r}
# Calculer la matrice de corr√©lation
corr_matrix <- cor(data[c('diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length')])

# Remodeler la matrice pour ggplot
melted_corr_matrix <- melt(corr_matrix)

# Cr√©er le heatmap avec ggplot2
ggplot(data = melted_corr_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "yellow") +
  geom_text(aes(label = sprintf("%.2f", value)), vjust = 1, color = "black", size = 3) +
  scale_fill_gradientn(colors = brewer.pal(n = 9, name = "BuPu")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Heatmap de la Matrice de Corr√©lation", x = "", y = "")
```

La variable la plus corr√©l√©e √† 'margin_low' est la variable 'length'.  
Le coefficient de corr√©lation est de -0.67, elle est significativement et n√©gativement corr√©l√©e √† cette variable.

### 3- Nuage de points 'margin_low' vs 'length'

Nous allons cr√©er un nuage de points pour les variables margin_low et length afin de mieux comprendre leur corr√©lation.

```{r}
# Cr√©er le scatter plot avec ggplot2
ggplot(data, aes(x = margin_low, y = length, color = is_genuine)) +
  geom_point() +  # Ajouter les points avec la couleur bas√©e sur is_genuine
  scale_color_manual(values = c(True = "skyblue", False = "purple")) +  # D√©finir les couleurs pour TRUE et FALSE
  labs(title = "Scatter Plot de margin_low vs length",
       x = "Margin Low",
       y = "Length",
       color = "Is Genuine") +  # Ajouter une l√©gende pour la couleur
  theme_minimal() +                # Utiliser un th√®me minimaliste
  theme(axis.text.x = element_text(angle = 45, hjust = 1), # Rotation des labels si n√©cessaire
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold")) # Centrer le titre
```
On remarque une tendance grace au scatter plot :
- plus la longueur "length" est faible,  
- plus la marge basse "margin_low" est haute
Cela marque √©galement significativement la diff√©rence entre vrais et faux billets :
- les vrais billets ont une longueur √©lev√©e et une marge_low faible
- les faux billets ont une longueur faible et une marge_low √©lev√©e.

### 4- V√©rification de la corr√©lation entre 'margin_low' et 'length'
#### a- Normalit√© de la distribution ? viualisation Graphique
##### Histogrammes

```{r}
# Histogramme et courbe de densit√© pour margin_low
ggplot(data, aes(x = margin_low)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogramme et courbe de densit√© pour margin_low",
       x = "Margin Low",
       y = "Density") +
  theme_minimal()

# Histogramme et courbe de densit√© pour length
ggplot(data, aes(x = length)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogramme et courbe de densit√© pour length",
       x = "Length",
       y = "Density") +
  theme_minimal()

```

##### Q-Q plots

```{r}
# Q-Q Plot pour margin_low
ggplot(data, aes(sample = margin_low)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot pour margin_low",
       x = "Th√©orique Quantiles",
       y = "Quantiles Observ√©s") +
  theme_minimal()

# Q-Q Plot pour length
ggplot(data, aes(sample = length)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot pour length",
       x = "Th√©orique Quantiles",
       y = "Quantiles Observ√©s") +
  theme_minimal()

```

#### b- Normalit√© de la distribution ? tests math√©matiques
##### Shapiro-Wilk

H0 : les 2 variables suivent une distribution normale (si p-value > 0.05)
H1 : les 2 variables ne suivent pas une distribution normale (si p-value < 0.05)

```{r}
# Test de Shapiro-Wilk pour margin_low
shapiro_test_margin_low <- shapiro.test(data$margin_low)
print(shapiro_test_margin_low)

# Test de Shapiro-Wilk pour length
shapiro_test_length <- shapiro.test(data$length)
print(shapiro_test_length)

```

H0 est rejet√©e car au moins une des 2 variables ne suit pas une distribution normale avec p-value < 0.05 et proche de 0.

p-value tr√®s faible (< 2.2e-16) :

La p-value tr√®s inf√©rieure √† 0.05 indique que nous rejetons l'hypoth√®se nulle dans les deux cas. Autrement dit, il est extr√™mement improbable que les donn√©es suivent une distribution normale.

Statistiques 
ùëä
W :

Les statistiques 
ùëä
W (0.93752 pour margin_low et 0.9176 pour length) sont inf√©rieures √† 1, ce qui sugg√®re que les donn√©es s'√©cartent de la normalit√©.

Les r√©sultats des tests de Shapiro-Wilk indiquent que ni margin_low ni length ne suivent une distribution normale.

##### Kolmogorov-Smirnov

```{r}
# Test de Kolmogorov-Smirnov pour margin_low
ks_test_margin_low <- ks.test(data$margin_low, "pnorm", mean = mean(data$margin_low), sd = sd(data$margin_low))
print(ks_test_margin_low)

# Test de Kolmogorov-Smirnov pour length
ks_test_length <- ks.test(data$length, "pnorm", mean = mean(data$length), sd = sd(data$length))
print(ks_test_length)

```

Statistique 
ùê∑
D :

La statistique 
ùê∑
D mesure la plus grande diff√©rence entre la distribution empirique des donn√©es et la distribution normale th√©orique. Une statistique 
ùê∑
D plus grande indique une plus grande d√©viation de la normalit√©.

p-value :

La p-value tr√®s faible (< 2.2e-16) indique que nous rejetons l'hypoth√®se nulle selon laquelle les donn√©es suivent une distribution normale. Cela sugg√®re que les donn√©es de margin_low et length s'√©cartent significativement d'une distribution normale.

Les r√©sultats du test de Kolmogorov-Smirnov confirment les conclusions des tests de Shapiro-Wilk : les donn√©es ne suivent pas une distribution normale.

#### c- Test de corr√©lation des rangs de Spearman

Dans le cas d'une distribution non gaussienne nous utilisons le coefficient de corr√©lation des rangs de Spearman pour d√©terminer math√©matiquement s'il y a une corr√©lation entre 2 variables quantitatives.

```{r}
# Effectuer le test de corr√©lation de Spearman entre margin_low et length
test_spearman <- cor.test(data$margin_low, data$length, method = "spearman")

# Afficher les r√©sultats
print(test_spearman)

```

### R√©gr√©ssion lin√©aire multiple
#### V√©rifier la multicolin√©arit√© avec statistiques VIF (Variance Inflation Factory)

```{r}
if (!require(car)) install.packages("car")
library(car)

# Pr√©parer les donn√©es : retirer les lignes avec des valeurs manquantes
data_clean <- na.omit(data[, c("margin_low", "diagonal", "height_left", "height_right", "margin_up", "length")])

# Cr√©er le mod√®le de r√©gression
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data_clean)

# Calculer les valeurs VIF
vif_values <- vif(model)

# Afficher les valeurs VIF
print(vif_values)
```

R√®gles G√©n√©rales :

VIF < 5 : Pas de multicolin√©arit√© significative.
5 ‚â§ VIF < 10 : Multicolin√©arit√© mod√©r√©e.
VIF ‚â• 10 : Multicolin√©arit√© √©lev√©e.

Les r√©sultats montrent que la multicolin√©arit√© entre les variables pr√©dictives n'est pas un probl√®me majeur dans le mod√®le. Les valeurs VIF sont toutes relativement faibles, ce qui est un bon signe pour la stabilit√© et l'interpr√©tabilit√© du mod√®le de r√©gression lin√©aire.

#### Validation crois√©e

La validation crois√©e permet de tester la performance du mod√®le sur plusieurs sous-ensembles de donn√©es pour √©valuer sa capacit√© √† g√©n√©raliser.

```{r}
if (!require(caret)) install.packages("caret")
library(caret)

# D√©finir les contr√¥les de validation crois√©e
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

# Cr√©er le mod√®le de r√©gression
model <- train(margin_low ~ diagonal + height_left + height_right + margin_up + length,
               data = data_clean, 
               method = "lm", 
               trControl = train_control)

# Afficher les r√©sultats de la validation crois√©e
print(model)
```

#### Analyse des R√©sidus

Examine les r√©sidus pour v√©rifier les hypoth√®ses de la r√©gression lin√©aire, notamment l'homosc√©dasticit√© (variance constante des erreurs) et la normalit√© des r√©sidus.

```{r}
# Cr√©er un mod√®le de r√©gression
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data_clean)

# Plot des r√©sidus
par(mfrow = c(2, 2))  # Afficher plusieurs graphiques dans une grille 2x2
plot(model)  # Affiche les graphiques des r√©sidus

```
Les graphiques g√©n√©r√©s sont :

Residuals vs Fitted: V√©rifie si les r√©sidus sont al√©atoires.
Normal Q-Q: V√©rifie la normalit√© des r√©sidus.
Scale-Location: V√©rifie l'homosc√©dasticit√©.
Residuals vs Leverage: Identifie les points influents.

#### √âvaluation des Performances

√âvalue la performance du mod√®le en utilisant des m√©triques telles que le R¬≤, l'erreur quadratique moyenne (RMSE) et l'erreur absolue moyenne (MAE).

```{r}
# Calculer les pr√©dictions sur les donn√©es de validation
predictions <- predict(model, newdata = data_clean)

# Calculer les m√©triques de performance
actuals <- data_clean$margin_low
rmse <- sqrt(mean((predictions - actuals)^2))
mae <- mean(abs(predictions - actuals))
r_squared <- summary(model)$r.squared

# Afficher les r√©sultats
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r_squared, "\n")

```

RMSE (Root Mean Square Error) : Le RMSE de 0.4746 obtenu lors de la validation crois√©e et de 0.4733 sur l'ensemble de test montre que le mod√®le est coh√©rent entre l'entra√Ænement et le test.
MAE (Mean Absolute Error) : Le MAE de 0.3642 lors de la validation crois√©e et de 0.3597 sur l'ensemble de test indique que les erreurs moyennes absolues sont √©galement faibles, ce qui est un bon signe.
R¬≤ (Coefficient de D√©termination) : Un R¬≤ d'environ 0.48-0.49 montre que le mod√®le explique environ 48-49% de la variance des donn√©es, ce qui n'est pas exceptionnel, mais peut √™tre satisfaisant en fonction de la complexit√© du probl√®me.

#### D√©tection des Points Influents

Il est √©galement important d'identifier les points influents qui pourraient avoir un impact disproportionn√© sur le mod√®le.

```{r}
# Calculer les valeurs de Cook's distance
cooks_d <- cooks.distance(model)

# Identifier les points influents
influential_points <- which(cooks_d > (4 / nrow(data_clean)))

# Afficher les points influents
cat("Points influents :", influential_points, "\n")

```

```{r}
# Extraire et afficher les lignes correspondantes dans le dataframe 'data'
influential_data <- data[influential_points, ]
print(influential_data)
```

#### Validation avec un Ensemble de Test

Si possible, r√©serve un sous-ensemble de tes donn√©es pour tester le mod√®le apr√®s l'entra√Ænement. Cela te permettra de v√©rifier la performance sur des donn√©es non vues.

```{r}
# Diviser les donn√©es en ensembles d'entra√Ænement et de test
set.seed(123)  # Pour la reproductibilit√©
train_index <- createDataPartition(data_clean$margin_low, p = 0.7, list = FALSE)
train_data <- data_clean[train_index, ]
test_data <- data_clean[-train_index, ]

# Cr√©er et entra√Æner le mod√®le sur les donn√©es d'entra√Ænement
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = train_data)

# Pr√©dictions sur les donn√©es de test
predictions <- predict(model, newdata = test_data)

# Calculer les m√©triques de performance sur les donn√©es de test
actuals <- test_data$margin_low
rmse_test <- sqrt(mean((predictions - actuals)^2))
mae_test <- mean(abs(predictions - actuals))
r_squared_test <- summary(lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = test_data))$r.squared

# Afficher les r√©sultats de la validation sur les donn√©es de test
cat("Test RMSE:", rmse_test, "\n")
cat("Test MAE:", mae_test, "\n")
cat("Test R-squared:", r_squared_test, "\n")

```


## V- Remplacement des donn√©es manquantes

R√©gression lin√©aire

```{r}
# √âtape 1: Cr√©ation du mod√®le de r√©gression lin√©aire
# Mod√®le avec toutes les variables disponibles pour pr√©dire margin_low
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = data)
```

```{r}
# √âtape 2: Pr√©dire les valeurs manquantes
# Cr√©er une copie du dataframe avec les NA
data_na <- data[is.na(data$margin_low), ]
```

```{r}
data_na
```

```{r}
# Pr√©dire les valeurs manquantes
predicted_values <- predict(model, newdata = data_na)
```

```{r}
predicted_values
```

```{r}
# √âtape 3: Remplacer les NA par les valeurs pr√©dites
data$margin_low[is.na(data$margin_low)] <- predicted_values
```

```{r}
# Voir le r√©sultat
summary(data$margin_low)
```

```{r}
skim(data)
```

```{r}
# Obtenir les r√©sidus du mod√®le
residus <- residuals(model)

# R√©sum√© des r√©sidus
summary(residus)

# Visualiser les r√©sidus
hist(residus, main="Distribution des r√©sidus", xlab="R√©sidus")

```

```{r}
# R√©sum√© du mod√®le de r√©gression lin√©aire
summary(model)

```

Le mod√®le de r√©gression lin√©aire a √©t√© ajust√© avec succ√®s, et voici ce que signifient les r√©sultats :

### 1. **R√©sidus**

Les r√©sidus montrent la diff√©rence entre les valeurs observ√©es et les valeurs pr√©dites par le mod√®le.

-   **Min** : -1.47234
-   **1Q (premier quartile)** : -0.31707
-   **Median** : -0.04168
-   **3Q (troisi√®me quartile)** : 0.27353
-   **Max** : 1.97084

Ces chiffres montrent que la plupart des erreurs de pr√©diction se situent dans une plage de -1.47 √† 1.97, avec une m√©diane proche de 0, ce qui est un bon signe. La distribution des r√©sidus semble √©quilibr√©e, on peut v√©rifier cela avec un histogramme ou un graphique Q-Q pour confirmer.

### 2. **Coefficients**

Les coefficients indiquent l'effet de chaque variable pr√©dictrice sur la variable d√©pendante `margin_low`, tout en tenant compte des autres variables.

-   **Intercept (22.99484)** : La valeur de `margin_low` lorsque toutes les autres variables sont √† 0 (pas toujours significatif dans la pratique, surtout si les valeurs 0 ne sont pas r√©alistes pour ces variables).

-   **diagonal (-0.11106)** : Une augmentation d'une unit√© dans `diagonal` est associ√©e √† une diminution de `margin_low` de 0.11106 unit√©s, avec une significativit√© statistique (p-value = 0.00744).

-   **height_left (0.18412)** : Une augmentation d'une unit√© dans `height_left` est associ√©e √† une augmentation de `margin_low` de 0.18412 unit√©s (tr√®s significatif avec p-value = 4.13e-05).

-   **height_right (0.25714)** : Une augmentation d'une unit√© dans `height_right` est associ√©e √† une augmentation de `margin_low` de 0.25714 unit√©s (tr√®s significatif, p-value = 2.84e-09).

-   **margin_up (0.25619)** : Une augmentation d'une unit√© dans `margin_up` est associ√©e √† une augmentation de `margin_low` de 0.25619 unit√©s (tr√®s significatif, p-value = 7.23e-05).

-   **length (-0.40910)** : Une augmentation d'une unit√© dans `length` est associ√©e √† une diminution de `margin_low` de 0.40910 unit√©s (tr√®s significatif, p-value \< 2e-16).

### 3. **Signification statistique**

-   Les p-values indiquent que tous les coefficients sont statistiquement significatifs au niveau de 0.05, voire beaucoup plus bas (beaucoup d'√©toiles `***`).
-   **Signif. codes** : Les niveaux de significativit√© sont indiqu√©s avec `*`, `**`, `***`, etc. Ici, tous les pr√©dicteurs sont tr√®s significatifs, sauf l'intercept.

### 4. **Erreur standard r√©siduelle (Residual Standard Error)**

-   **Residual Standard Error** : 0.4807. C'est l'√©cart-type des r√©sidus, une mesure de la dispersion des observations autour des pr√©dictions. Cela signifie que, en moyenne, les pr√©dictions de `margin_low` sont √† 0.4807 unit√©s des valeurs observ√©es.

### 5. **R-squared et Adjusted R-squared**

-   **Multiple R-squared** : 0.4773. Cela signifie que 47.73% de la variance dans `margin_low` est expliqu√©e par ce mod√®le.
-   **Adjusted R-squared** : 0.4755. C'est une version ajust√©e du R-squared qui p√©nalise l'ajout de pr√©dicteurs non significatifs. Ici, c'est tr√®s proche du R-squared, ce qui est bon signe.

### 6. **F-statistic**

-   **F-statistic** : 266.1 avec un p-value tr√®s bas (\< 2.2e-16), indiquant que le mod√®le dans son ensemble est statistiquement significatif.

### Conclusion

Le mod√®le est relativement bon, avec un R-squared autour de 0.4773, ce qui montre une relation mod√©r√©e entre les variables pr√©dictrices et `margin_low`. Tous les pr√©dicteurs sont statistiquement significatifs, et l'erreur standard r√©siduelle est relativement basse, ce qui indique que les pr√©dictions ne s'√©cartent pas trop des valeurs observ√©es.

Cependant, on pourrait am√©liorer encore la pr√©cision en explorant d'autres mod√®les, v√©rifier l'absence de colin√©arit√© entre les pr√©dicteurs, ou en ajoutant d'autres variables si elles sont disponibles. on pourrait aussi v√©rifier les r√©sidus pour s'assurer qu'ils sont normalement distribu√©s et qu'il n'y a pas de probl√®me avec l'homosc√©dasticit√© (variance constante des r√©sidus).

## VI- ACP et Clustering

### 1- Recherche de valeurs aberrantes

```{r}
# Boxplot pour chaque variable num√©rique
data_numeric <- data %>% select(where(is.numeric))

# Afficher boxplots
par(mfrow = c(2, 3))  # Adapter le nombre de graphiques selon le nombre de variables
for (col in colnames(data_numeric)) {
  boxplot(data_numeric[[col]], main = col, ylab = col)
}

```

```{r}
# Scatter plot entre deux variables
plot(data$diagonal, data$height_left, main = "Diagonale vs. Hauteur gauche", xlab = "Diagonale", ylab = "Hauteur gauche")

```

#### a- M√©thode IQR

```{r}
# Calculer l'IQR pour chaque colonne
iqr <- function(x) {
  q3 <- quantile(x, 0.75)
  q1 <- quantile(x, 0.25)
  q3 - q1
}

# D√©tecter les outliers pour chaque colonne
outliers <- function(x) {
  q1 <- quantile(x, 0.25)
  q3 <- quantile(x, 0.75)
  iqr_value <- iqr(x)
  lower_bound <- q1 - 1.5 * iqr_value
  upper_bound <- q3 + 1.5 * iqr_value
  x < lower_bound | x > upper_bound
}
```

```{r}
# Appliquer la fonction pour d√©tecter les outliers
iqr_outliers_data <- data_numeric %>%
  mutate(across(everything(), ~ outliers(.)))

# Afficher les outliers
head(iqr_outliers_data)
```

```{r}
# Afficher les indices des outliers
iqr_outliers_indices <- which(rowSums(iqr_outliers_data) > 0)
print(iqr_outliers_indices)
```

```{r}
# Afficher les lignes du dataframe original contenant des outliers
data_with_iqr_outliers <- data[iqr_outliers_indices, ]

print(data_with_iqr_outliers)
```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
iqr_count_by_is_genuine <- data_with_iqr_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du r√©sultat
print(iqr_count_by_is_genuine)

```

Il y a 53 lignes d'outliers avec la m√©thode IQR\
40 lignes concernent des faux billets\
13 lignes concernent de vrais billets

#### b- M√©thode Z_score

```{r}
if (!require(tidyverse)) install.packages("tidyverse")

# Charger les biblioth√®ques n√©cessaires
library(tidyverse)

# S√©lectionner les colonnes num√©riques
data_numeric <- data %>% select(where(is.numeric))

# Calculer les scores Z
data_z <- scale(data_numeric)

# V√©rifier les scores Z
head(data_z)

```

```{r}
summary(data_z)
```

```{r}
# Ajouter les scores Z au dataframe original en conservant la colonne de caract√®res
data_z_full <- cbind(Row_Index = 1:nrow(data), data %>% select(where(is.character)), as.data.frame(data_z))

# Afficher les premi√®res lignes du nouveau dataframe
head(data_z_full)

```

```{r}
# Visualiser la distribution des scores Z pour la colonne 'diagonal'
ggplot(as.data.frame(data_z), aes(x=diagonal)) + 
  geom_histogram(binwidth=0.5, fill="blue", color="black") + 
  theme_minimal() +
  labs(title="Distribution des scores Z pour la colonne 'diagonal'")
```

On fixe √† +3 et -3 la limite de z_score pour identifier les outliers

```{r}
# Identifier les lignes avec des outliers (Z > 3 ou Z < -3)
z_outliers <- data_z_full %>%
  filter(apply(data_z, 1, function(row) any(row > 3 | row < -3)))

# Afficher les outliers
print(z_outliers)

```
```{r}
data_bis <- data
# Ajouter une colonne Row_index bas√©e sur l'index de ligne
data_bis$Row_Index <- 1:nrow(data_bis)

```


```{r}
data_bis
```

```{r}
# Fusionner z_outliers avec la colonne is_genuine de data en utilisant Row_index
z_outliers <- merge(z_outliers, data_bis[, c("Row_Index", "is_genuine")], by = "Row_Index")

z_outliers
```

```{r}
library(dplyr)

# Comptage du nombre de lignes par groupe dans la colonne is_genuine
z_count_by_is_genuine <- z_outliers %>%
  group_by(is_genuine) %>%
  summarise(count = n())

# Affichage du r√©sultat
print(z_count_by_is_genuine)

```

```{r}
# Extraire les indices des outliers
z_outliers_indices <- z_outliers$Row_Index
z_outliers_indices
```

Il y a 24 lignes d'outliers avec la m√©thode du Z_score\
17 lignes concernent des faux billets\
7 lignes concernent de vrais billets

### 2- Suppression des lignes d'outliers

Je vais commencer mon analyse en supprimant les outliers identifi√©s par la m√©thode du Z_Score\
Je vais donc supprimer 24 lignes du dataframe original "data"\
je le nommerai "data_without_ouliers_z"

```{r}
data_without_ouliers_z <- data[-z_outliers_indices, ]
data_without_ouliers_z
```

### 3- ACP

```{r}
if (!require(FactoMineR)) install.packages("FactoMineR")
if (!require(factoextra)) install.packages("factoextra")

library(FactoMineR)
library(factoextra)
```

```{r}
# Extraire les colonnes num√©riques
datanum_without_ouliers_z <- Filter(is.numeric, data_without_ouliers_z)
```

```{r}
# R√©aliser l'ACP sans sp√©cifier ncp
resultat_acp <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, graph = FALSE)

# Extraire les valeurs propres
valeurs_propres <- resultat_acp$eig[,1]
```

```{r}
# Calculer les pourcentages d'inertie expliqu√©e par chaque composante
pourcentage_inertie <- 100 * valeurs_propres / sum(valeurs_propres)
# Calculer l'inertie cumul√©e
cumulative_inertia <- cumsum(pourcentage_inertie)
```

```{r}
# Cr√©er un graphique avec un seul appel
par(mfrow = c(1, 1)) # Assurez-vous d'avoir une seule fen√™tre graphique

# Cr√©er un plot avec des barres pour les pourcentages d'inertie
barplot(pourcentage_inertie, main = "√âboulis des Composantes Principales",
        xlab = "Composante Principale", ylab = "Pourcentage d'Inertie",
        col = "lightblue", border = "blue", ylim = c(0, 100))

# Ajouter la courbe cumul√©e en superposition sur le m√™me graphique
# Recr√©er le graphique avec la courbe cumul√©e en utilisant `plot` pour ne pas effacer les barres
par(new = TRUE) # Permet de superposer le nouveau graphique sur le pr√©c√©dent
plot(cumulative_inertia, type = "o", col = "red", pch = 19, 
     ylim = c(0, 100), xlab = "", ylab = "", axes = FALSE)

# Ajouter une l√©gende
legend("topright", legend = c("Inertie Cumul√©e (%)"), col = "red", pch = 19, inset = c(0, 0.5))
```

```{r}
# on choisit 4 composantes principales qui repr√©sentent 80% de la variance
resultat_acp_optimal <- PCA(datanum_without_ouliers_z, scale.unit = TRUE, ncp = 4, graph = FALSE)

```

```{r}
# Visualiser les individus et les variables pour les premi√®res et derni√®res combinaisons de composantes
pairs_to_plot <- list(c(1, 2), c(3, 4))  # Choisir les paires de composantes √† afficher

# Visualiser les individus et les variables pour les diff√©rentes combinaisons de composantes
for (pair in pairs_to_plot) {
# Visualiser les individus
  print(fviz_pca_ind(resultat_acp_optimal, 
                     axes = pair, 
                     col.ind = "cos2", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
                     repel = TRUE) +
        ggtitle(paste("Visualisation des Individus - Composantes", pair[1], "et", pair[2])))
  
  # Visualiser les variables
  print(fviz_pca_var(resultat_acp_optimal, 
                     axes = pair, 
                     col.var = "contrib", 
                     gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")) +
        ggtitle(paste("Visualisation des Variables - Composantes", pair[1], "et", pair[2])))
}
```

Axes principaux :\
Dim1 (45.9%) : Cet axe explique 45.9% de la variance totale des donn√©es.\
Dim2 (14.6%) : Cet axe explique 14.6% de la variance totale des donn√©es.

Dim1 On observe :\
- une forte contribution positibe de la marge basse (margin_low)\
- une forte contribution n√©gative de la longueur (length)\
une forte valeur de Dim1 indiquera un longueur de billet faible avec une marge basse √©lev√©e

Dim2 On observe :\
- une forte contribution positibe de la diagonale Une forte valeur de Dim2 indiquera une valeur de diagonale √©lev√©e

```{r}
# Extraire les scores des individus
scores <- resultat_acp_optimal$ind$coord

```

```{r}
head(scores)
```

### 4- Clustering

```{r}
# D√©finir une plage de nombres de clusters √† tester
k_values <- 1:10  # Tester de 1 √† 10 clusters
wss <- numeric(length(k_values))  # Pour stocker la somme des carr√©s intra-cluster

# Calculer l'inertie pour chaque nombre de clusters
for (k in k_values) {
  kmeans_result <- kmeans(scores, centers = k, nstart = 25)  # nstart pour la reproductibilit√©
  wss[k] <- kmeans_result$tot.withinss
}

# Tracer la m√©thode du coude
plot(k_values, wss, type = "b", pch = 19, col = "blue", 
     xlab = "Nombre de Clusters", ylab = "Somme des Carr√©s Intra-Cluster",
     main = "M√©thode du Coude pour K-means Clustering")
```

```{r}
# Appliquer K-means clustering avec 2 clusters
kmeans_result <- kmeans(scores, centers = 2, nstart = 23)  # nstart pour la reproductibilit√©

```

```{r}
# Installer et charger le package factoextra si ce n'est pas d√©j√† fait
if (!require(factoextra)) install.packages("factoextra")
library(factoextra)

# Installer et charger le package ggplot2 si ce n'est pas d√©j√† fait
if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

# Visualiser les clusters dans les deux premi√®res composantes principales
plot_clusters <- fviz_cluster(kmeans_result, data = scores,
                              ellipse.type = "euclid",  # Ajouter des ellipses autour des clusters
                              ggtheme = theme_minimal()) +
  ggtitle("Clustering K-means avec 2 Clusters")

# Ajouter les centres des clusters au graphique
centroids <- kmeans_result$centers

plot_clusters + 
  geom_point(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2), 
             color = "red", size = 5, shape = 8) +  # Points rouges pour les centres
  geom_text(data = as.data.frame(centroids), aes(x = Dim.1, y = Dim.2, label = rownames(centroids)),
            color = "black", vjust = -1, hjust = 1)  # √âtiquettes pour les centres


```

```{r}
# Centres des clusters
print(kmeans_result$centers)

```

```{r}
# Taille de chaque cluster
print(kmeans_result$size)

```

```{r}
# Ajouter les r√©sultats du clustering √† un DataFrame
data_with_clusters <- data.frame(data_without_ouliers_z, Cluster = kmeans_result$cluster)

# Afficher les premi√®res lignes du DataFrame avec les clusters
head(data_with_clusters)

```

```{r}
count_values  <- data_with_clusters %>%
  group_by(Cluster, is_genuine) %>%
  count()

print(count_values)
  
```
